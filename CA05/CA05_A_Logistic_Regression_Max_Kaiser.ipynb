{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CA05_A_Logistic_Reression_Max_Kaiser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaI78ch6tVYw"
      },
      "source": [
        "# Your name: Max Kaiser \n",
        "## Assignment Name: CA05 - Logistic Regression \n",
        "\n",
        "# Program Inititialization Section\n",
        "## Enter your import packages here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEq8lEoRtVYy"
      },
      "source": [
        "# import packages \n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #plot AUC \n",
        "from sklearn import linear_model \n",
        "\n",
        "from sklearn import linear_model \n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpF-vmlXtVYy"
      },
      "source": [
        "# Data File Reading Section\n",
        "## Write code to read in data from external sources here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mhq99hYAtVYy",
        "outputId": "1287e8af-5685-4f89-d957-e006f1d508e6"
      },
      "source": [
        "#read datasets\n",
        "\n",
        "#df = pd.read_csv('cvd_data.csv',na_values='NA')\n",
        "\n",
        "df = pd.read_csv('https://github.com/ArinB/CA05-B-Logistic-Regression/raw/master/cvd_data.csv',na_values='NA')\n",
        "\n",
        "df.head(5)\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cvd_4types</th>\n",
              "      <th>age_s1</th>\n",
              "      <th>race</th>\n",
              "      <th>educat</th>\n",
              "      <th>mstat</th>\n",
              "      <th>hip</th>\n",
              "      <th>neck20</th>\n",
              "      <th>waist</th>\n",
              "      <th>av_weight_kg</th>\n",
              "      <th>cgpkyr</th>\n",
              "      <th>tea15</th>\n",
              "      <th>srhype</th>\n",
              "      <th>parrptdiab</th>\n",
              "      <th>bend25</th>\n",
              "      <th>happy25</th>\n",
              "      <th>tired25</th>\n",
              "      <th>hlthlm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>110.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>87.5</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>113.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>110.0</td>\n",
              "      <td>44.5</td>\n",
              "      <td>105.0</td>\n",
              "      <td>86.2</td>\n",
              "      <td>49.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>129.0</td>\n",
              "      <td>42.5</td>\n",
              "      <td>110.0</td>\n",
              "      <td>89.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>81.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cvd_4types  age_s1  race  educat  ...  bend25  happy25  tired25  hlthlm25\n",
              "0           0      54     1       2  ...       1        2        3         4\n",
              "1           0      56     3       2  ...       2        2        1         3\n",
              "2           0      54     1       3  ...       3        2        6         4\n",
              "3           0      54     1       3  ...       3        2        1         3\n",
              "4           0      51     3       2  ...       2        1        1         2\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSDAvG-ptVYz"
      },
      "source": [
        "# **Data Quality Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "CKxCS8FvtVY0",
        "outputId": "c8f84a59-338a-4a09-8e76-134a1b0aab6c"
      },
      "source": [
        "#Q1\n",
        "df.describe().round(1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cvd_4types</th>\n",
              "      <th>age_s1</th>\n",
              "      <th>race</th>\n",
              "      <th>educat</th>\n",
              "      <th>mstat</th>\n",
              "      <th>hip</th>\n",
              "      <th>neck20</th>\n",
              "      <th>waist</th>\n",
              "      <th>av_weight_kg</th>\n",
              "      <th>cgpkyr</th>\n",
              "      <th>tea15</th>\n",
              "      <th>srhype</th>\n",
              "      <th>parrptdiab</th>\n",
              "      <th>bend25</th>\n",
              "      <th>happy25</th>\n",
              "      <th>tired25</th>\n",
              "      <th>hlthlm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "      <td>3242.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.6</td>\n",
              "      <td>64.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>105.4</td>\n",
              "      <td>37.6</td>\n",
              "      <td>97.2</td>\n",
              "      <td>82.9</td>\n",
              "      <td>12.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.5</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>10.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>13.6</td>\n",
              "      <td>7.8</td>\n",
              "      <td>20.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>34.4</td>\n",
              "      <td>88.0</td>\n",
              "      <td>78.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>37.2</td>\n",
              "      <td>97.0</td>\n",
              "      <td>82.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>106.0</td>\n",
              "      <td>86.6</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>136.7</td>\n",
              "      <td>170.5</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cvd_4types  age_s1    race  educat  ...  bend25  happy25  tired25  hlthlm25\n",
              "count      3242.0  3242.0  3242.0  3242.0  ...  3242.0   3242.0   3242.0    3242.0\n",
              "mean          0.6    64.8     1.1     2.3  ...     2.5      2.3      4.3       3.9\n",
              "std           0.5    10.4     0.4     0.7  ...     0.7      1.0      1.0       0.6\n",
              "min           0.0    39.0     1.0     1.0  ...     1.0      1.0      1.0       1.0\n",
              "25%           0.0    57.0     1.0     2.0  ...     2.0      2.0      4.0       4.0\n",
              "50%           1.0    65.0     1.0     2.0  ...     3.0      2.0      4.0       4.0\n",
              "75%           1.0    73.0     1.0     3.0  ...     3.0      3.0      5.0       4.0\n",
              "max           1.0    90.0     3.0     4.0  ...     3.0      6.0      6.0       5.0\n",
              "\n",
              "[8 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ3cNQZStVY0",
        "outputId": "948968c1-ab2a-4a5e-c340-f714bfa684f8"
      },
      "source": [
        "#Q2\n",
        "df.shape\n",
        "# 17 columns \n",
        "# 3242 rows "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3242, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Fqo9W3tVY0",
        "outputId": "faa6a047-c51b-4f30-88ca-88d6c5095ab4"
      },
      "source": [
        "#Q3\n",
        "df.count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cvd_4types      3242\n",
              "age_s1          3242\n",
              "race            3242\n",
              "educat          3242\n",
              "mstat           3242\n",
              "hip             3242\n",
              "neck20          3242\n",
              "waist           3242\n",
              "av_weight_kg    3242\n",
              "cgpkyr          3242\n",
              "tea15           3242\n",
              "srhype          3242\n",
              "parrptdiab      3242\n",
              "bend25          3242\n",
              "happy25         3242\n",
              "tired25         3242\n",
              "hlthlm25        3242\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtb7xrGMtVY1",
        "outputId": "9d195e67-cd2e-4491-f54c-c540a36b0870"
      },
      "source": [
        "#Q4 \n",
        "df.isnull().sum()\n",
        "#no missing values "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cvd_4types      0\n",
              "age_s1          0\n",
              "race            0\n",
              "educat          0\n",
              "mstat           0\n",
              "hip             0\n",
              "neck20          0\n",
              "waist           0\n",
              "av_weight_kg    0\n",
              "cgpkyr          0\n",
              "tea15           0\n",
              "srhype          0\n",
              "parrptdiab      0\n",
              "bend25          0\n",
              "happy25         0\n",
              "tired25         0\n",
              "hlthlm25        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITI4D01otVY1",
        "outputId": "7c14445a-8426-41a8-9518-4fd3c7f9cc48"
      },
      "source": [
        "#Q5 \n",
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3242 entries, 0 to 3241\n",
            "Data columns (total 17 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   cvd_4types    3242 non-null   int64  \n",
            " 1   age_s1        3242 non-null   int64  \n",
            " 2   race          3242 non-null   int64  \n",
            " 3   educat        3242 non-null   int64  \n",
            " 4   mstat         3242 non-null   int64  \n",
            " 5   hip           3242 non-null   float64\n",
            " 6   neck20        3242 non-null   float64\n",
            " 7   waist         3242 non-null   float64\n",
            " 8   av_weight_kg  3242 non-null   float64\n",
            " 9   cgpkyr        3242 non-null   float64\n",
            " 10  tea15         3242 non-null   int64  \n",
            " 11  srhype        3242 non-null   int64  \n",
            " 12  parrptdiab    3242 non-null   int64  \n",
            " 13  bend25        3242 non-null   int64  \n",
            " 14  happy25       3242 non-null   int64  \n",
            " 15  tired25       3242 non-null   int64  \n",
            " 16  hlthlm25      3242 non-null   int64  \n",
            "dtypes: float64(5), int64(12)\n",
            "memory usage: 430.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "cNJzpcJRtVY1",
        "outputId": "153f7b9a-0643-400f-de44-f288e66604b9"
      },
      "source": [
        "#Q6 Top 10 \n",
        "df.head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cvd_4types</th>\n",
              "      <th>age_s1</th>\n",
              "      <th>race</th>\n",
              "      <th>educat</th>\n",
              "      <th>mstat</th>\n",
              "      <th>hip</th>\n",
              "      <th>neck20</th>\n",
              "      <th>waist</th>\n",
              "      <th>av_weight_kg</th>\n",
              "      <th>cgpkyr</th>\n",
              "      <th>tea15</th>\n",
              "      <th>srhype</th>\n",
              "      <th>parrptdiab</th>\n",
              "      <th>bend25</th>\n",
              "      <th>happy25</th>\n",
              "      <th>tired25</th>\n",
              "      <th>hlthlm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>110.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>87.5</td>\n",
              "      <td>34.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>113.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>110.0</td>\n",
              "      <td>44.5</td>\n",
              "      <td>105.0</td>\n",
              "      <td>86.2</td>\n",
              "      <td>49.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>129.0</td>\n",
              "      <td>42.5</td>\n",
              "      <td>110.0</td>\n",
              "      <td>89.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>81.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>140.0</td>\n",
              "      <td>35.5</td>\n",
              "      <td>101.0</td>\n",
              "      <td>87.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>101.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>80.5</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>107.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>73.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>36.5</td>\n",
              "      <td>89.0</td>\n",
              "      <td>79.1</td>\n",
              "      <td>6.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>105.0</td>\n",
              "      <td>35.5</td>\n",
              "      <td>90.0</td>\n",
              "      <td>78.1</td>\n",
              "      <td>21.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cvd_4types  age_s1  race  educat  ...  bend25  happy25  tired25  hlthlm25\n",
              "0           0      54     1       2  ...       1        2        3         4\n",
              "1           0      56     3       2  ...       2        2        1         3\n",
              "2           0      54     1       3  ...       3        2        6         4\n",
              "3           0      54     1       3  ...       3        2        1         3\n",
              "4           0      51     3       2  ...       2        1        1         2\n",
              "5           0      67     1       3  ...       1        1        4         4\n",
              "6           0      68     1       2  ...       2        3        4         4\n",
              "7           0      67     1       2  ...       2        2        4         4\n",
              "8           0      44     1       2  ...       3        3        4         4\n",
              "9           0      42     1       2  ...       3        2        3         3\n",
              "\n",
              "[10 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "9TGV-qFNtVY1",
        "outputId": "33b34920-669b-4b20-866b-b0ea9b76d2d4"
      },
      "source": [
        "#Q6 Bottom 10 \n",
        "df.tail(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cvd_4types</th>\n",
              "      <th>age_s1</th>\n",
              "      <th>race</th>\n",
              "      <th>educat</th>\n",
              "      <th>mstat</th>\n",
              "      <th>hip</th>\n",
              "      <th>neck20</th>\n",
              "      <th>waist</th>\n",
              "      <th>av_weight_kg</th>\n",
              "      <th>cgpkyr</th>\n",
              "      <th>tea15</th>\n",
              "      <th>srhype</th>\n",
              "      <th>parrptdiab</th>\n",
              "      <th>bend25</th>\n",
              "      <th>happy25</th>\n",
              "      <th>tired25</th>\n",
              "      <th>hlthlm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3232</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>117.0</td>\n",
              "      <td>35.5</td>\n",
              "      <td>107.0</td>\n",
              "      <td>88.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3233</th>\n",
              "      <td>1</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>114.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>85.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3234</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>93.0</td>\n",
              "      <td>29.5</td>\n",
              "      <td>81.0</td>\n",
              "      <td>76.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3235</th>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>104.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>87.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3236</th>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>115.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>84.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3237</th>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>41.5</td>\n",
              "      <td>99.0</td>\n",
              "      <td>88.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3238</th>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>34.9</td>\n",
              "      <td>99.0</td>\n",
              "      <td>83.3</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3239</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>101.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>75.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3240</th>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3241</th>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>109.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>112.0</td>\n",
              "      <td>93.5</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cvd_4types  age_s1  race  educat  ...  bend25  happy25  tired25  hlthlm25\n",
              "3232           1      55     1       4  ...       3        1        5         4\n",
              "3233           1      71     1       1  ...       1        3        4         4\n",
              "3234           1      55     1       3  ...       3        2        4         4\n",
              "3235           1      59     1       1  ...       3        2        5         4\n",
              "3236           1      54     1       2  ...       3        2        5         4\n",
              "3237           1      66     1       2  ...       2        2        5         4\n",
              "3238           1      54     1       3  ...       3        3        3         4\n",
              "3239           1      55     1       4  ...       3        2        5         4\n",
              "3240           1      53     1       2  ...       2        2        5         4\n",
              "3241           1      54     1       2  ...       3        2        5         4\n",
              "\n",
              "[10 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeBVl6S02hHT"
      },
      "source": [
        "# **Model Building**\n",
        "\n",
        "Binary Classifier - Predict CVD Risk (Yes/No, or 1/0) using a Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIdAzb0C2mnV"
      },
      "source": [
        "1. Store the feature matrix (X) and response vector (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeCw-IzV2lIV"
      },
      "source": [
        "\n",
        "# always capital letter X, vector small y\n",
        "# X = Matri(2-dimensional) all data \n",
        "# y = response variable\n",
        "\n",
        "y = df.cvd_4types\t\n",
        "X = df.drop('cvd_4types', axis= 1)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOPgWOLM4lYC",
        "outputId": "8ea9f851-66dc-4644-e33f-4ba3dbd57cae"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3242, 16)\n",
            "(3242,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bolVnFCSi9S",
        "outputId": "56c0ebf9-f82c-4ef2-adf7-d75a2a25db74"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "logit_model = sm.Logit(y,X)\n",
        "result=logit_model.fit()\n",
        "print(result.summary2())"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.607367\n",
            "         Iterations 5\n",
            "                         Results: Logit\n",
            "=================================================================\n",
            "Model:              Logit            Pseudo R-squared: 0.103     \n",
            "Dependent Variable: cvd_4types       AIC:              3970.1708 \n",
            "Date:               2021-03-26 02:24 BIC:              4067.5139 \n",
            "No. Observations:   3242             Log-Likelihood:   -1969.1   \n",
            "Df Model:           15               LL-Null:          -2194.3   \n",
            "Df Residuals:       3226             LLR p-value:      1.6785e-86\n",
            "Converged:          1.0000           Scale:            1.0000    \n",
            "No. Iterations:     5.0000                                       \n",
            "------------------------------------------------------------------\n",
            "               Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
            "------------------------------------------------------------------\n",
            "age_s1         0.0143    0.0035   4.0551  0.0001   0.0074   0.0212\n",
            "race          -0.9012    0.1185  -7.6023  0.0000  -1.1336  -0.6689\n",
            "educat         0.3242    0.0571   5.6828  0.0000   0.2124   0.4361\n",
            "mstat         -0.1299    0.0406  -3.1989  0.0014  -0.2094  -0.0503\n",
            "hip           -0.0392    0.0048  -8.1243  0.0000  -0.0487  -0.0298\n",
            "neck20        -0.0219    0.0123  -1.7907  0.0733  -0.0460   0.0021\n",
            "waist          0.0709    0.0054  13.0546  0.0000   0.0602   0.0815\n",
            "av_weight_kg  -0.0179    0.0065  -2.7432  0.0061  -0.0307  -0.0051\n",
            "cgpkyr         0.0000    0.0020   0.0156  0.9875  -0.0039   0.0039\n",
            "tea15         -0.0541    0.0300  -1.8023  0.0715  -0.1130   0.0047\n",
            "srhype         0.0961    0.0876   1.0967  0.2728  -0.0756   0.2678\n",
            "parrptdiab     0.5611    0.1709   3.2823  0.0010   0.2260   0.8961\n",
            "bend25         0.2354    0.0621   3.7898  0.0002   0.1137   0.3571\n",
            "happy25       -0.0174    0.0416  -0.4186  0.6755  -0.0990   0.0642\n",
            "tired25        0.1423    0.0427   3.3329  0.0009   0.0586   0.2259\n",
            "hlthlm25      -0.4576    0.0687  -6.6614  0.0000  -0.5922  -0.3229\n",
            "=================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCz1dg2USuCj"
      },
      "source": [
        "Removing variables/features with p-values greater than 0.05. (statistically not significant)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeIMsRBuS0aU",
        "outputId": "53242407-7005-431a-e96c-80b7a237c5c6"
      },
      "source": [
        "#columns to remove (neck20,cgpkyr,srhype,happy25,tea15)\n",
        "\n",
        "col = ['age_s1','race','educat','mstat','hip','waist','av_weight_kg','parrptdiab','bend25','tired25','hlthlm25']\n",
        "\n",
        "\n",
        "# X only with significant feature columns \n",
        "X = X[col]\n",
        "\n",
        "# response variable y stays the same \n",
        "\n",
        "logit_model = sm.Logit(y,new_X)\n",
        "result=logit_model.fit()\n",
        "print(result.summary2())"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.608680\n",
            "         Iterations 5\n",
            "                         Results: Logit\n",
            "=================================================================\n",
            "Model:              Logit            Pseudo R-squared: 0.101     \n",
            "Dependent Variable: cvd_4types       AIC:              3968.6828 \n",
            "Date:               2021-03-26 02:25 BIC:              4035.6062 \n",
            "No. Observations:   3242             Log-Likelihood:   -1973.3   \n",
            "Df Model:           10               LL-Null:          -2194.3   \n",
            "Df Residuals:       3231             LLR p-value:      1.1113e-88\n",
            "Converged:          1.0000           Scale:            1.0000    \n",
            "No. Iterations:     5.0000                                       \n",
            "------------------------------------------------------------------\n",
            "               Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
            "------------------------------------------------------------------\n",
            "age_s1         0.0145    0.0034   4.2092  0.0000   0.0077   0.0212\n",
            "race          -0.9074    0.1181  -7.6836  0.0000  -1.1388  -0.6759\n",
            "educat         0.3086    0.0566   5.4512  0.0000   0.1977   0.4196\n",
            "mstat         -0.1307    0.0405  -3.2298  0.0012  -0.2100  -0.0514\n",
            "hip           -0.0392    0.0047  -8.2850  0.0000  -0.0484  -0.0299\n",
            "waist          0.0674    0.0049  13.6364  0.0000   0.0577   0.0771\n",
            "av_weight_kg  -0.0220    0.0062  -3.5728  0.0004  -0.0341  -0.0099\n",
            "parrptdiab     0.5630    0.1704   3.3047  0.0010   0.2291   0.8969\n",
            "bend25         0.2160    0.0614   3.5148  0.0004   0.0955   0.3364\n",
            "tired25        0.1396    0.0414   3.3720  0.0007   0.0585   0.2207\n",
            "hlthlm25      -0.4812    0.0680  -7.0799  0.0000  -0.6145  -0.3480\n",
            "=================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGm0oOMc7ffh"
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFL2tgIH-7BZ",
        "outputId": "868f9ffa-7b6d-4995-80e3-963bb41a79ce"
      },
      "source": [
        "# Fit (train) the Logistic Regression classifier \n",
        "\n",
        "clf = linear_model.LogisticRegression(C=1e40,solver='newton-cg')\n",
        "\n",
        "fitted_model = clf.fit(X,y)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHWGZfxmAOK4",
        "outputId": "4969d129-9514-45d7-e2c3-a5d08549c1d4"
      },
      "source": [
        "# 2-dimensional numpy array\n",
        "#1st column is the predicted porbability of class 0 (no risk) for each \n",
        "#observation\n",
        "#2nd column is the predicted porbability of class 1 (risk) for each \n",
        "#observation\n",
        "\n",
        "clf.predict_proba(X_test)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42926454, 0.57073546],\n",
              "       [0.42586143, 0.57413857],\n",
              "       [0.51268155, 0.48731845],\n",
              "       ...,\n",
              "       [0.67264383, 0.32735617],\n",
              "       [0.45216873, 0.54783127],\n",
              "       [0.33318248, 0.66681752]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM-aCFpYGRcm",
        "outputId": "2ec5a013-760a-400d-9cd3-7e8420127b96"
      },
      "source": [
        "# now calculating the predicted probability of risk = 1 for each testing set observation\n",
        "# I want all rows and only the 2nd column (at risk column) by using [:, 1]\n",
        "clf.predict_proba(X_test)[:, 1]\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.57073546, 0.57413857, 0.48731845, 0.55302168, 0.65568438,\n",
              "       0.47795347, 0.12550107, 0.34870578, 0.80783376, 0.63327909,\n",
              "       0.5039416 , 0.66571849, 0.79118164, 0.83803663, 0.6732719 ,\n",
              "       0.52240678, 0.32306787, 0.77934111, 0.53506381, 0.90704895,\n",
              "       0.71366344, 0.60795979, 0.47315024, 0.56088901, 0.50426164,\n",
              "       0.22247385, 0.56194375, 0.42548877, 0.2768639 , 0.57054396,\n",
              "       0.52161796, 0.70656571, 0.77389692, 0.79756339, 0.59496007,\n",
              "       0.52260443, 0.65231415, 0.58361905, 0.62964992, 0.51554087,\n",
              "       0.27772315, 0.44155402, 0.71126392, 0.4691188 , 0.74675666,\n",
              "       0.31630359, 0.6411198 , 0.90015528, 0.64738983, 0.59962927,\n",
              "       0.67403738, 0.70840215, 0.63797914, 0.59301273, 0.26669024,\n",
              "       0.08216517, 0.55818973, 0.76978274, 0.63209817, 0.8343744 ,\n",
              "       0.80966318, 0.76796579, 0.77255605, 0.55460561, 0.2384385 ,\n",
              "       0.71857313, 0.25243125, 0.12364425, 0.59215055, 0.53059197,\n",
              "       0.59172048, 0.73200733, 0.76222463, 0.7246431 , 0.25230249,\n",
              "       0.54791067, 0.62348086, 0.74340571, 0.60020077, 0.23089509,\n",
              "       0.591759  , 0.39728753, 0.22364854, 0.49826863, 0.76480143,\n",
              "       0.68068075, 0.86777217, 0.73684351, 0.3134496 , 0.79758172,\n",
              "       0.71133293, 0.73646872, 0.69767937, 0.8780881 , 0.79788245,\n",
              "       0.84286199, 0.17118517, 0.73849342, 0.72301822, 0.34153946,\n",
              "       0.79185106, 0.66377971, 0.35344633, 0.65106313, 0.60417007,\n",
              "       0.79409112, 0.34421671, 0.43413618, 0.2338294 , 0.65537448,\n",
              "       0.76274243, 0.59685182, 0.78548615, 0.7152954 , 0.63183941,\n",
              "       0.70545454, 0.44802345, 0.37713096, 0.64042226, 0.72905763,\n",
              "       0.52053118, 0.47091642, 0.48325217, 0.69597995, 0.56071073,\n",
              "       0.49761949, 0.76438776, 0.29653748, 0.48258626, 0.73290175,\n",
              "       0.56364584, 0.49022919, 0.74299235, 0.60537542, 0.3870985 ,\n",
              "       0.73407943, 0.74603943, 0.70127629, 0.50200908, 0.80967311,\n",
              "       0.67793944, 0.75302964, 0.70789173, 0.72892318, 0.62484717,\n",
              "       0.34468129, 0.73695508, 0.56305793, 0.78257162, 0.06426485,\n",
              "       0.31158167, 0.46559589, 0.73616304, 0.55146619, 0.66956944,\n",
              "       0.5364257 , 0.66870902, 0.70951746, 0.57796059, 0.77764354,\n",
              "       0.48057752, 0.42821287, 0.37676632, 0.46839766, 0.56598281,\n",
              "       0.71280641, 0.61225457, 0.83316904, 0.31439765, 0.61214281,\n",
              "       0.64076123, 0.76489046, 0.68041521, 0.77331009, 0.57485951,\n",
              "       0.51359567, 0.64807537, 0.7126398 , 0.77531297, 0.77435782,\n",
              "       0.67696211, 0.63593507, 0.65644119, 0.79055918, 0.22937051,\n",
              "       0.61870284, 0.51622146, 0.68650066, 0.71319338, 0.26728742,\n",
              "       0.67655055, 0.5696191 , 0.70239921, 0.69509048, 0.5591994 ,\n",
              "       0.46146514, 0.6446487 , 0.67506987, 0.49097287, 0.65016029,\n",
              "       0.62417803, 0.56097315, 0.37777892, 0.80284237, 0.54123719,\n",
              "       0.56818719, 0.49856446, 0.43173404, 0.67648259, 0.45572256,\n",
              "       0.43456778, 0.39805326, 0.1528195 , 0.57933664, 0.31740662,\n",
              "       0.44096148, 0.73683714, 0.75655803, 0.74166305, 0.19480262,\n",
              "       0.74588511, 0.35450793, 0.3096041 , 0.45572824, 0.62511164,\n",
              "       0.50781939, 0.63149994, 0.48513558, 0.75274237, 0.49685943,\n",
              "       0.66757616, 0.57044618, 0.3270051 , 0.40775283, 0.66419262,\n",
              "       0.61047873, 0.53439351, 0.47946632, 0.51863896, 0.46306117,\n",
              "       0.67044011, 0.57949304, 0.63950117, 0.21033606, 0.32533494,\n",
              "       0.77924855, 0.8031138 , 0.41377648, 0.83996191, 0.27321512,\n",
              "       0.69498665, 0.24632962, 0.84200876, 0.47806056, 0.71998867,\n",
              "       0.43657704, 0.8152023 , 0.4307897 , 0.82417972, 0.55966719,\n",
              "       0.37582238, 0.74127019, 0.82705687, 0.68783236, 0.58696299,\n",
              "       0.77271633, 0.83914137, 0.60504785, 0.67139375, 0.68568043,\n",
              "       0.54363392, 0.29226233, 0.82209293, 0.40830751, 0.41164716,\n",
              "       0.63891776, 0.74459835, 0.33445129, 0.61006775, 0.64262785,\n",
              "       0.73610917, 0.60849434, 0.6030627 , 0.60715819, 0.56291959,\n",
              "       0.82774604, 0.3436143 , 0.5958967 , 0.72643914, 0.70435176,\n",
              "       0.12712455, 0.33535409, 0.67267177, 0.70649067, 0.71470237,\n",
              "       0.48242315, 0.47653782, 0.59428966, 0.6350436 , 0.7342796 ,\n",
              "       0.5923802 , 0.71546744, 0.32735791, 0.55236244, 0.48163575,\n",
              "       0.26340151, 0.63526833, 0.51679975, 0.44282463, 0.58330403,\n",
              "       0.76753558, 0.72839659, 0.57787919, 0.28565673, 0.65885445,\n",
              "       0.52134046, 0.65919845, 0.83188845, 0.31580357, 0.63200432,\n",
              "       0.23310049, 0.55913308, 0.80087193, 0.18491653, 0.77833483,\n",
              "       0.74565167, 0.62092452, 0.65231591, 0.67737322, 0.81539926,\n",
              "       0.27565124, 0.66687154, 0.49376232, 0.87236609, 0.47796981,\n",
              "       0.25061377, 0.37479446, 0.66205727, 0.59048117, 0.67344727,\n",
              "       0.65279422, 0.68688947, 0.55491077, 0.52979143, 0.45515466,\n",
              "       0.74445758, 0.81300944, 0.59494743, 0.4086759 , 0.61414967,\n",
              "       0.68408454, 0.66487825, 0.75826787, 0.67715464, 0.45931426,\n",
              "       0.72246797, 0.62492448, 0.64833109, 0.83865173, 0.54655733,\n",
              "       0.60599538, 0.86601069, 0.57115582, 0.76316997, 0.60825963,\n",
              "       0.55592086, 0.68872457, 0.81142345, 0.55877543, 0.43932013,\n",
              "       0.77129972, 0.544955  , 0.63512832, 0.81650859, 0.68180417,\n",
              "       0.60555731, 0.84826962, 0.31991758, 0.4860902 , 0.46373137,\n",
              "       0.22004027, 0.59598277, 0.55789902, 0.34954555, 0.33038427,\n",
              "       0.71050908, 0.8444091 , 0.5152867 , 0.71307565, 0.10820652,\n",
              "       0.51710254, 0.78957362, 0.7413296 , 0.11096384, 0.59471534,\n",
              "       0.54014748, 0.66850117, 0.78886749, 0.23756012, 0.67905778,\n",
              "       0.61374273, 0.25993182, 0.79558871, 0.44334966, 0.56974907,\n",
              "       0.83556146, 0.57751204, 0.57910319, 0.51989053, 0.36336969,\n",
              "       0.88542153, 0.57331299, 0.39112953, 0.76015308, 0.67218044,\n",
              "       0.20837996, 0.76021665, 0.81152387, 0.82998815, 0.76586099,\n",
              "       0.83254543, 0.76585957, 0.81311193, 0.52571068, 0.69538976,\n",
              "       0.7298588 , 0.52988828, 0.56093062, 0.49359481, 0.7076925 ,\n",
              "       0.52529985, 0.17560995, 0.65730255, 0.7337489 , 0.3939686 ,\n",
              "       0.65725762, 0.85618438, 0.74245439, 0.13459453, 0.89902822,\n",
              "       0.62296349, 0.09146664, 0.63984527, 0.84285423, 0.74925194,\n",
              "       0.23515741, 0.7305405 , 0.77201734, 0.68023467, 0.43813154,\n",
              "       0.55041419, 0.07583459, 0.6461487 , 0.50249713, 0.6996365 ,\n",
              "       0.58306115, 0.26260371, 0.54550783, 0.53267471, 0.65551217,\n",
              "       0.56776293, 0.54309206, 0.74147928, 0.30650693, 0.63699838,\n",
              "       0.71452424, 0.67737516, 0.49680453, 0.73903574, 0.82286596,\n",
              "       0.55799618, 0.46385862, 0.6738035 , 0.66862367, 0.81895403,\n",
              "       0.69446476, 0.72481301, 0.80478284, 0.58733913, 0.76589562,\n",
              "       0.8318308 , 0.35257199, 0.4713047 , 0.61501286, 0.59859858,\n",
              "       0.66119647, 0.56901467, 0.70556928, 0.17933541, 0.89329609,\n",
              "       0.54038381, 0.43176732, 0.50764264, 0.47188037, 0.69739755,\n",
              "       0.29219186, 0.32129437, 0.51900839, 0.83910512, 0.74330065,\n",
              "       0.64258563, 0.85607766, 0.84816745, 0.74798162, 0.64483611,\n",
              "       0.70680076, 0.60028647, 0.6853813 , 0.49521037, 0.66820668,\n",
              "       0.59001046, 0.57308646, 0.63999168, 0.75576349, 0.54562306,\n",
              "       0.65991792, 0.42546837, 0.54086168, 0.83613211, 0.66434326,\n",
              "       0.56646732, 0.55670144, 0.4074838 , 0.7044001 , 0.73719653,\n",
              "       0.6286665 , 0.72658352, 0.81728572, 0.35130716, 0.65245392,\n",
              "       0.6317454 , 0.83669758, 0.76277574, 0.25074051, 0.43304081,\n",
              "       0.65178764, 0.57111965, 0.45632873, 0.68721936, 0.41293421,\n",
              "       0.42080514, 0.54434609, 0.66105277, 0.74760218, 0.62921565,\n",
              "       0.59115992, 0.5691801 , 0.43200108, 0.49504102, 0.43217735,\n",
              "       0.67142681, 0.38660792, 0.79126247, 0.71068445, 0.50062453,\n",
              "       0.72302799, 0.56696156, 0.67038241, 0.32049474, 0.07799006,\n",
              "       0.77638008, 0.73247713, 0.04895032, 0.64129179, 0.48347616,\n",
              "       0.13348738, 0.60707401, 0.70368497, 0.70752912, 0.36017723,\n",
              "       0.65019424, 0.62574821, 0.30105646, 0.43754959, 0.72945141,\n",
              "       0.58430051, 0.66030462, 0.6835339 , 0.54323234, 0.71211432,\n",
              "       0.82433059, 0.66973698, 0.18765316, 0.45318385, 0.6302411 ,\n",
              "       0.55971147, 0.72621971, 0.12387907, 0.29741506, 0.17968721,\n",
              "       0.39290175, 0.74618865, 0.56424222, 0.80036447, 0.4629038 ,\n",
              "       0.43723063, 0.21526782, 0.49239024, 0.59668673, 0.49287714,\n",
              "       0.54639503, 0.68518838, 0.55998266, 0.28385746, 0.51929073,\n",
              "       0.55226508, 0.69064773, 0.53314376, 0.68001959, 0.57480372,\n",
              "       0.59285748, 0.21671808, 0.71746258, 0.73157607, 0.71470518,\n",
              "       0.65088865, 0.66075082, 0.62599648, 0.58444782, 0.56706735,\n",
              "       0.91152872, 0.5642081 , 0.47950836, 0.57682176, 0.73351387,\n",
              "       0.73889893, 0.88184803, 0.65994843, 0.5290362 , 0.52983645,\n",
              "       0.34300427, 0.20557414, 0.88064361, 0.5574957 , 0.71755328,\n",
              "       0.76228091, 0.80228935, 0.52485046, 0.54556275, 0.51643518,\n",
              "       0.57806961, 0.61592408, 0.63687724, 0.80187341, 0.58977734,\n",
              "       0.43400736, 0.87320141, 0.86506147, 0.78409049, 0.25302221,\n",
              "       0.5353447 , 0.55428363, 0.6260049 , 0.57380174, 0.86641391,\n",
              "       0.42615739, 0.48983268, 0.79675009, 0.31911163, 0.1669358 ,\n",
              "       0.38334033, 0.57519428, 0.74286291, 0.69403853, 0.31278412,\n",
              "       0.64418931, 0.52680849, 0.68651085, 0.18073778, 0.542252  ,\n",
              "       0.33188544, 0.64698303, 0.54498073, 0.83111243, 0.60826289,\n",
              "       0.52231003, 0.45864782, 0.77806513, 0.3556652 , 0.75303211,\n",
              "       0.78219184, 0.68489516, 0.66695619, 0.88023299, 0.33386351,\n",
              "       0.65383747, 0.64692449, 0.78269637, 0.60895356, 0.42298619,\n",
              "       0.78141312, 0.91053392, 0.68571022, 0.56445922, 0.91047414,\n",
              "       0.66484449, 0.5701735 , 0.62662138, 0.36685961, 0.75389929,\n",
              "       0.72052264, 0.74274525, 0.62228099, 0.59115439, 0.67212787,\n",
              "       0.62065733, 0.52743028, 0.4692584 , 0.61655119, 0.75464191,\n",
              "       0.82899577, 0.58030935, 0.34331844, 0.5120168 , 0.58578726,\n",
              "       0.48619316, 0.80505834, 0.76767749, 0.52053919, 0.81982158,\n",
              "       0.54757317, 0.89430869, 0.67249584, 0.59034149, 0.22565614,\n",
              "       0.70908127, 0.78018259, 0.80892955, 0.53604552, 0.55206848,\n",
              "       0.69883908, 0.60467375, 0.56389183, 0.83031497, 0.58272789,\n",
              "       0.29080886, 0.55162912, 0.36339382, 0.63132019, 0.11480697,\n",
              "       0.75470469, 0.88368594, 0.59834646, 0.13552566, 0.76458737,\n",
              "       0.16843943, 0.46862412, 0.61876861, 0.57175709, 0.67636415,\n",
              "       0.23289035, 0.36715936, 0.2417217 , 0.61040239, 0.68228513,\n",
              "       0.56178654, 0.65498763, 0.75897045, 0.60291794, 0.55320436,\n",
              "       0.75291905, 0.4848717 , 0.59079016, 0.79246242, 0.73833207,\n",
              "       0.75079871, 0.71415892, 0.74881842, 0.37817938, 0.81415967,\n",
              "       0.77230263, 0.60724676, 0.72384   , 0.83222784, 0.62388881,\n",
              "       0.56364661, 0.44954109, 0.75579613, 0.72930673, 0.86257582,\n",
              "       0.70153802, 0.6422819 , 0.66325386, 0.57437132, 0.7467344 ,\n",
              "       0.81682575, 0.65112798, 0.41367033, 0.75749032, 0.65489168,\n",
              "       0.56374343, 0.81956444, 0.41408386, 0.88808476, 0.44748995,\n",
              "       0.58596255, 0.93027659, 0.37599705, 0.42619451, 0.39005807,\n",
              "       0.36002949, 0.74777846, 0.73863211, 0.735611  , 0.27570783,\n",
              "       0.73669466, 0.68527003, 0.87347607, 0.32735617, 0.54783127,\n",
              "       0.66681752])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO1mSVtVGog-"
      },
      "source": [
        "y_pred_prob= clf.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x234Kg0eAMJh",
        "outputId": "1e5e5bf7-ea35-496f-e69f-ce8278a050a6"
      },
      "source": [
        "#calculate the AUC\n",
        "from sklearn import metrics\n",
        "print('AUC:',metrics.roc_auc_score(y_test, y_pred_prob))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.7355365047775779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgzeEB-hVKmJ",
        "outputId": "1ccf87d6-991c-495b-c26f-922c42728c4f"
      },
      "source": [
        "#accuracy (fraction of correct predictions) --> correct predictions / total number of data points\n",
        "\n",
        "# Using the score method to get accuracy of model\n",
        "print('Accuracy score:',clf.score(X_test, y_test))\n",
        "\n",
        "#Source:\n",
        "#https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.6091245376078915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6393cFDMVnPG"
      },
      "source": [
        "# **Part 2 (Feature Importance)**\n",
        "\n",
        "**Display the Feature Importance of all the features sorted in the order of decreasing influence on the CVD Risk**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "9RANXLwgV1x-",
        "outputId": "20a57ef7-9c67-44e7-ee20-14e706b03b6e"
      },
      "source": [
        "clf.fit(X/ np.std(X, 0),y)\n",
        "\n",
        "#the higher the absolute value of a feature coefficient --> importance\n",
        "\n",
        "coef_table = pd.DataFrame(abs(clf.coef_), columns= col).transpose().sort_values(by=0,ascending=False)\n",
        "coef_table.rename(columns={0: \"coef\"},inplace=True)\n",
        "\n",
        "coef_table\n"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>waist</th>\n",
              "      <td>1.008078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hip</th>\n",
              "      <td>0.548939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race</th>\n",
              "      <td>0.362810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hlthlm25</th>\n",
              "      <td>0.359956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>av_weight_kg</th>\n",
              "      <td>0.271942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>educat</th>\n",
              "      <td>0.180753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parrptdiab</th>\n",
              "      <td>0.153321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mstat</th>\n",
              "      <td>0.133919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tired25</th>\n",
              "      <td>0.130611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bend25</th>\n",
              "      <td>0.087885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_s1</th>\n",
              "      <td>0.051074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  coef\n",
              "waist         1.008078\n",
              "hip           0.548939\n",
              "race          0.362810\n",
              "hlthlm25      0.359956\n",
              "av_weight_kg  0.271942\n",
              "educat        0.180753\n",
              "parrptdiab    0.153321\n",
              "mstat         0.133919\n",
              "tired25       0.130611\n",
              "bend25        0.087885\n",
              "age_s1        0.051074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwoCLZtffsWE"
      },
      "source": [
        "The features waist, hip, race, hlthlm25,av_weight_kg have the largest influence on the outcome (target variable). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN7ebcD1MAiQ"
      },
      "source": [
        "# **Part 3 (ROC Curve)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WcIWhs-5Hn8v",
        "outputId": "13416859-f282-4ce1-bfbd-f9656c34d928"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "logit_roc_auc = roc_auc_score(y_test, clf.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Research on how to plot ROC curve \n",
        "\n",
        "#Source:https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
